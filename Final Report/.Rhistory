latest_covid_cluster_df = covid_cluster_df %>% filter(date == max(date))
# compute our own COVID-19 risk
latest_covid_cluster_df = latest_covid_cluster_df %>% mutate(covid_risk = (0.32*new_cases_smoothed_per_million) +
(0.33*new_deaths_smoothed_per_million) -
(0.35*stringency_index))
# label countries by their COVID-19 risks as of 2022-05-12
latest_covid_cluster_df = latest_covid_cluster_df %>%
mutate(covid_risk_std = scale(covid_risk, center = TRUE, scale = TRUE),
covid_risk_class = case_when(
(covid_risk_std <= quantile(covid_risk_std, 0.33)) ~ "Low",
(covid_risk_std > quantile(covid_risk_std, 0.33) & covid_risk_std <= quantile(covid_risk_std, 0.67)) ~ "Medium",
(covid_risk_std > quantile(covid_risk_std, 0.67)) ~ "High"))
# label counries by their travel restrictions as of 2022-05-12
stringnecy_ind_std = covid_imputed_df %>%
mutate(stringency_index_std = scale(stringency_index, center = TRUE, scale = TRUE)) %>%
dplyr::select(date, location, stringency_index_std)
latest_stringency_ind_std = stringnecy_ind_std %>%
filter(date == "2022-05-12") %>%
mutate(travel_restrictions = case_when(
(stringency_index_std <= quantile(stringency_index_std, 0.33)) ~ "Low",
(stringency_index_std > quantile(stringency_index_std, 0.33) &
stringency_index_std <= quantile(stringency_index_std, 0.67)) ~ "Medium",
(stringency_index_std > quantile(stringency_index_std, 0.67)) ~ "High"))
# save the latest COVID-19 clusters
latest_covid_df = merge(latest_covid_cluster_df, latest_stringency_ind_std %>% dplyr::select(date, location, travel_restrictions), by = c("date", "location"))
write.csv(latest_covid_df, "latest_covid_cluster.csv")
# read socioeconomics index file
datasetA_3 <- read.csv(file = 'index_cleaned.csv', row.names = NULL)
# remove location "Armenia" due to missing data
datasetA_3 = datasetA_3 %>%
filter(Location != "Armenia")
# select year 2022 for most recent index data
datasetA_3 <- datasetA_3[ (datasetA_3$year == 2022), ]
# filter variables that is going to be used for analysis
col_names = c("Location", "Cost.of.Living.Index", "Rent.Index", 'Groceries.Index', "Restaurant.Price.Index", "Safety.Index", "Crime.Index")
data_new = datasetA_3[col_names]
# change column names as more readable ones
colnames(data_new) <- c("location", "cost", "rent", "groceries", "restaurant", "safety", "crime")
# view first 6 rows of the data
kable(head(data_new))
# view data summary
print(summarytools::dfSummary(data_new), method = "render")
# compute correlation of all numeric variables
M = cor(data_new[2:7])
# visualise correlation analysis
corrplot(M, method = 'color', order = 'alphabet', tl.cex = 0.8)
# visualise outliers using boxplot
results <- data_new[2:7]
boxplot(results)$out
# Minimise outliers by replacing outlier values by median
results$rent[results$rent %in% boxplot(results)$out] <- median(results$rent)
results$groceries[results$groceries %in% boxplot(results)$out] <- median(results$groceries)
results$cost[results$cost %in% boxplot(results)$out] <- median(results$cost)
results$restaurant[results$restaurant %in% boxplot(results)$out] <- median(results$restaurant)
results$safety[results$safety %in% boxplot(results)$out] <- median(results$safety)
results$crime[results$crime %in% boxplot(results)$out] <- median(results$crime)
# boxplot of the data with less outliers
boxplot(results)
# Removing the highly correlated features: groceries and restaurant
clean_data1 <- data_new[ -c(4:5) ]
results1 <- results[ -c(3:4) ]
# tandardise all numeric values:
results_z1 <- as.data.frame(lapply(results1, scale))
rownames(results_z1) = clean_data1$location
# find optimal value of k
# Elbow method
p1 = fviz_nbclust(results_z1, kmeans, method = "wss") +
geom_vline(xintercept = 5, linetype = 2) +
labs(subtitle = "Elbow method")
#silhouette method
p2 = fviz_nbclust(results_z1, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# Gap statistic
set.seed(2022)
p3 = fviz_nbclust(results_z1, kmeans,
nstart = 25,
method = "gap_stat",
nboot = 75
) +
labs(subtitle = "Gap statistic method")
#visualise plots above
lay <- rbind(c(1,2),
c(1,2),
c(3),
c(3))
grid.arrange(p3, p1, p2, layout_matrix = lay)
# kmeans clustering with k = 5
country_clusters <- kmeans(results_z1, 5)
# assigning cluster labels for each countries as a data frame
cluster_kmeans5 <- data.frame(clean_data1,
cluster = as.factor(country_clusters$cluster)
)
# Visualisation of k-means clustering with k = 5 using PCA
fviz_cluster(country_clusters, results_z1, ellipse.type = "norm", cex = 0.1)
# Silhouette coefficient of k = 5
sil <- silhouette(country_clusters$cluster, dist(results_z1))
p1 = fviz_silhouette(sil)
# k-means clustering: with k = 3
country_clusters2 <- kmeans(results_z1, 3)
# assigning cluster labels for each countries as a data frame
cluster_kmeans2 <- data.frame(clean_data1,
cluster = as.factor(country_clusters2$cluster)
)
# Visualisation of k-means clustering with k = 2 using PCA
fviz_cluster(country_clusters2, results_z1, ellipse.type = "norm", cex = 0.1)
# Silhouette coefficient of k = 3
sil <- silhouette(country_clusters2$cluster, dist(results_z1))
p2 = fviz_silhouette(sil)
# visualise ASW of both k = 3 and k = 5
lay <- rbind(c(1,2),
c(1,2))
grid.arrange(p1, p2, layout_matrix = lay)
# Hierarchical clustering with euclidean distance metric and average linkage method:
dist_data_euc <- dist(results_z1, method = "euclidean")
hc_countries_euc_ave <- hclust(dist_data_euc, method = "average")
# Visualising different linkage methods with Euclidean distance metrics:
hclust_methods <- c("ward.D", "single", "complete", "average", "mcquitty",
"median", "centroid", "ward.D2")
country_dendlist <- dendlist()
for(i in seq_along(hclust_methods)) {
hc_countries_euc <- hclust(dist_data_euc, method = hclust_methods[i])
country_dendlist <- dendlist(country_dendlist, as.dendrogram(hc_countries_euc))
}
names(country_dendlist) <- hclust_methods
par(mfrow = c(4,2))
par(cex = 0.4)
for(i in 1:8) {
country_dendlist[[i]] %>% set("branches_k_color", k=2) %>% plot(axes = FALSE)
title(names(country_dendlist)[i])
}
# Default distance metrics is Euclidean
# computing cophenetic coefficient for all different linkage method models below
dist_data = dist(results_z1)
h0=hclust(dist_data,method='ward.D')
h1=hclust(dist_data,method='single')
h2=hclust(dist_data,method='complete')
h3=hclust(dist_data,method='average')
h4=hclust(dist_data,method='mcquitty')
h5=hclust(dist_data,method='median')
h6=hclust(dist_data,method='centroid')
h7=hclust(dist_data,method='ward.D2')
c0=cophenetic(h0)
c1=cophenetic(h1)
c2=cophenetic(h2)
c3=cophenetic(h3)
c4=cophenetic(h4)
c5=cophenetic(h5)
c6=cophenetic(h6)
c7=cophenetic(h7)
cor1 = cor(dist_data,c0)
cor2 = cor(dist_data,c1)
cor3 = cor(dist_data,c2)
cor4 = cor(dist_data,c3)
cor5 = cor(dist_data,c4)
cor6 = cor(dist_data,c5)
cor7 = cor(dist_data,c6)
cor8 = cor(dist_data,c7)
methods = c("average","single", "complete", "ward.D")
correlations = c(cor4,cor2,cor3, cor1)
# computing agglomerative coefficient of the linakge methods below
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")
# function to compute coefficient
ac <- function(x) {
agnes(results_z1, method = x)$ac
}
# comparing results obtained above
df2 = data.frame(map_dbl(m, ac), correlations)
colnames(df2) = c("Agglomerative coefficient", "Cophenetic Coefficient")
# results table
kable(df2, digits = 3)
# computing agglomerate coefficients of different distance metrics
ag1 = agnes(results_z1, metric = "manhattan", method = "average")$ac
ag2 = agnes(results_z1, metric = "euclidean", method = "average")$ac
ag3 = agnes(results_z1, metric = "maximum", method = "average")$ac
res = c(ag1, ag2, ag3)
names_ag = c("Manhattan", "Euclidean", "Maximum")
df6 = data.frame(names_ag, res)
colnames(df6) = c("Distance Metrics", "Agglomerative Coefficient")
# resulting table
kable(df6, digits = 3)
# maximum distance hiearrchical clustering with average linkage
dist_data_max = dist(results_z1, method="maximum")
hc_countries_max_ave <- hclust(dist_data_max, method = "average")
# Manhattan distance hiearrchical clustering with average linkage
dist_data_man = dist(results_z1, method="manhattan")
hc_countries_man_ave <- hclust(dist_data_man, method = "average")
# Euclidean distance hiearrchical clustering with average linkage
dist_data_euc = dist(results_z1, method="euclidean")
hc_countries_euc_ave <- hclust(dist_data_euc, method = "average")
# computing agglomerate coefficients of different distance metrics
ag1 = agnes(results_z1, metric = "manhattan", method = "ward")$ac
ag2 = agnes(results_z1, metric = "euclidean", method = "ward")$ac
ag3 = agnes(results_z1, metric = "maximum", method = "ward")$ac
res = c(ag1, ag2, ag3)
names_ag = c("Manhattan", "Euclidean", "Maximum")
df6 = data.frame(names_ag, res)
colnames(df6) = c("Distance Metrics", "Agglomerative Coefficient")
# resulting table
kable(df6, digits = 3)
# maximum distance hiearrchical clustering with ward linakge
hc_countries_max_ward <- hclust(dist_data_max, method = "ward.D")
# manhattan distance hiearrchical clustering with ward linakge
hc_countries_man_ward <- hclust(dist_data_man, method = "ward.D")
# Finding the Optimal tree height to cut: Elbow method, Average Silhouette Method, and Gap Statistic Method
p1 = fviz_nbclust(results_z1, FUN = hcut, method = "silhouette") + labs(subtitle = "Silhouette method")
p2 = fviz_nbclust(results_z1, FUN = hcut, method = "wss") +
geom_vline(xintercept = 4, linetype = 2) +
labs(subtitle = "Elbow method")
set.seed(4)
gap_stat <- clusGap(results_z1, FUN = hcut, nstart = 25, K.max = 10, B = 50)
p3 = fviz_gap_stat(gap_stat) + labs(subtitle = "Gap statistics method")
lay <- rbind(c(1,2),
c(1,2),
c(3),
c(3))
# visualise plots above
grid.arrange(p3, p1, p2, layout_matrix = lay)
# cutting the tree with different k-values obtained above
# dendogram visualisation of different k
sub_grp4_ave <- cutree(hc_countries_euc_ave, k = 4) #cutting tree for k = 4
plot(hc_countries_euc_ave, cex = 0.6, main="Dendrogram of Average linkage method with k = 4",
xlab="Countries")
rect.hclust(hc_countries_euc_ave, k = 4, border = 2:4)
sub_grp5_ave <- cutree(hc_countries_euc_ave, k = 5) #cutting tree for k = 5
plot(hc_countries_euc_ave, cex = 0.6, main="Dendrogram of Average linkage method with k = 5",
xlab="Countries")
rect.hclust(hc_countries_euc_ave, k = 5, border = 2:4)
sub_grp2_ave <- cutree(hc_countries_euc_ave, k = 2) #cutting tree for k = 2
plot(hc_countries_euc_ave, cex = 0.6,  main="Dendrogram of Average linkage method with k = 2",
xlab="Countries")
rect.hclust(hc_countries_euc_ave, k = 2, border = 2:4)
# average linakge method
# Evaluate and compare for each different k using ASW
hc_cut5_ave <- hcut(results_z1, k = 5, hc_method = "average", hc_metric = "euclidean")
p1 = fviz_silhouette(hc_cut5_ave) + labs(title = "ASW of Hierarchical clustering algorithm with average linkage method and k = 5") # ASW plot
hc_cut4_ave <- hcut(results_z1, k = 4, hc_method = "average", hc_metric = "euclidean")
p2 = fviz_silhouette(hc_cut4_ave) + labs(title = "ASW of Hierarchical clustering algorithm with average linkage method and k = 4") # ASW plot
hc_cut2_ave <- hcut(results_z1, k = 2, hc_method = "average", hc_metric = "euclidean")
p3 = fviz_silhouette(hc_cut2_ave) + labs(title = "ASW of Hierarchical clustering algorithm with average linkage method and k = 4") # ASW plot
p1
p2
p3
# cutting the tree with different k-values obtained above
# dendogram visualisation of different k
sub_grp4_ward <- cutree(hc_countries_man_ward, k = 4) #cutting tree for k = 4
plot(hc_countries_man_ward, cex = 0.6, main="Dendrogram of Ward linkage method with k = 4",
xlab="Countries")
rect.hclust(hc_countries_man_ward, k = 4, border = 2:4)
sub_grp5_ward <- cutree(hc_countries_man_ward, k = 5) #cutting tree for k = 5
plot(hc_countries_man_ward, cex = 0.6, main="Dendrogram of Ward linkage method with k = 5",
xlab="Countries")
rect.hclust(hc_countries_man_ward, k = 5, border = 2:4)
sub_grp2_ward <- cutree(hc_countries_man_ward, k = 2) #cutting tree for k = 2
plot(hc_countries_man_ward, cex = 0.6, main="Dendrogram of Ward linkage method with k = 2",
xlab="Countries")
rect.hclust(hc_countries_man_ward, k = 2, border = 2:4)
# Evaluate and compare for different k, with linkage method "Ward.D" using ASW
hc_cut5_ward <- hcut(results_z1, k = 5, hc_method = "ward.D", hc_metric = "manhattan")
p1 = fviz_silhouette(hc_cut5_ward) + labs(title = "ASW of Hierarchical clustering algorithm with Ward's linkage method and k = 5") # ASW plot
hc_cut4_ward <- hcut(results_z1, k = 4, hc_method = "ward.D", hc_metric = "manhattan")
p2 = fviz_silhouette(hc_cut4_ward)+ labs(title = "ASW of Hierarchical clustering algorithm with Ward's linkage method and k = 4") # ASW plot
hc_cut2_ward <- hcut(results_z1, k = 2, hc_method = "ward.D", hc_metric = "manhattan")
p3 = fviz_silhouette(hc_cut2_ward)+ labs(title = "ASW of Hierarchical clustering algorithm with Ward's linkage method and k = 2") # ASW plot
p1
p2
p3
# compare Ward.D vs Average
# Result: Ward.D Linkage method
k = c(5, 4, 2)
Ward = c(0.39, 0.38, 0.43)
Average = c( 0.38, 0.32, 0.37)
df7 = data.frame(k, Ward, Average)
kable(df7)
# k-means -> k = 5
results1$cluster <- (country_clusters$cluster)
fviz_cluster(country_clusters, results_z1, ellipse.type = "norm", cex = 0.5) #visualise kmeans k = 5
df3 <- data.frame( withinss=country_clusters$withinss )
# hierarchical -> k = 5 with Ward.D linkage method, manhattan distance metrics
plot(hc_countries_man_ward, cex = 0.6)
rect.hclust(hc_countries_man_ward, k = 5, border = 2:4)
fviz_cluster(list(data = results_z1, cluster = sub_grp5_ward)) # visualise hierarchical clustering
country_cluster_data_hierarchical5 <- data.frame(clean_data1,
cluster = as.factor(sub_grp5_ward)
)
#boxplot of features in 5 clusters for within-cluster variability (k-means clusetering)
data_num_kmeans4 = cluster_kmeans5[2:6] #selecting features
data_long_kmeans4 = melt(data_num_kmeans4, id = "cluster")
gg1 = ggplot(data_long_kmeans4, aes(x = variable, y = value, color = cluster)) +
geom_boxplot() + labs(title = "K-means: Boxplot of 4 features in 5 clusters ") + scale_x_discrete(name ="Features") +
theme_bw()
gg1
#boxplotc of features in 5 clusters for within-cluster variability (hierarchical clustering)
data_num_hierarchical5 = country_cluster_data_hierarchical5[2:6]
data_long_hierarchical5 = melt(data_num_hierarchical5, id = "cluster")
ggplot(data_long_hierarchical5, aes(x = variable, y = value, color = cluster)) +
geom_boxplot()+ labs(title = "Hierarchical: Boxplot of 4 features in 5 clusters ") +
scale_x_discrete(name ="Features") +
theme_bw()
set.seed(100)
#compute dunn index for kmeans and hierarchical clustering algorithms obtained above
dunn_km2 <- dunn(clusters = country_clusters2$cluster, Data = results_z1)
dunn_km5 <- dunn(clusters = country_clusters$cluster, Data = results_z1)
dunn_h_ward_4 <- dunn(clusters = sub_grp4_ward, Data = results_z1)
dunn_h_ward_2 <- dunn(clusters = sub_grp2_ward, Data = results_z1)
dunn_h_ward_5 <- dunn(clusters = sub_grp5_ward, Data = results_z1)
Indexes = c(dunn_km2, dunn_km5, dunn_h_ward_4, dunn_h_ward_2, dunn_h_ward_5)
Models = c("k-means: k=2", "k-means: k=5", "hclust,ward: k=4", "hclust,ward: k=2", "hclust,ward: k=5")
df4 = data.frame(Models, Indexes)
#resulting table
kable(df4, digits = 3)
#stability
set.seed(3888)
n = 1000
result = c()
for (i in 1:n){
df.new <- results_z1[-sample(1:nrow(results_z1), 8), ] # randomly remove 10% of data
data_keep_rows = rownames(df.new)
data_subset <- country_cluster_data_hierarchical5[country_cluster_data_hierarchical5$location %in% data_keep_rows, ]
dist_data_man = dist(df.new, method="manhattan") #final model with manhattan distance
hc_countries_man_ward <- hclust(dist_data_man, method = "ward.D") #final model with ward linakge
sub_grp5_ward <- cutree(hc_countries_man_ward, k = 5) #final model with k = 5
mc_ari <- adjustedRandIndex(data_subset$cluster, sub_grp5_ward) #compute adjusted rand index
result[i] = mc_ari #store it in vector
}
round(mean(result), 2) # mean ari
result<-as.data.frame(result)
gg = ggplot(data = result, aes(x = result, y = NULL)) +
geom_boxplot(fill = "navy", alpha = 0.3) +
labs(x = "Adjusted Rand Index",
title = "Adjusted Rand Index Distribution of a 1000-time simulation\nfor the Stability of Hierarchical Clustering") +
theme_bw()
gg #visualise boxplot of ari 1000-time simulation
# combined figure for socioeconomic clusters
p1 = fviz_silhouette(hc_cut5_ward, font.title = 10, print.summary = FALSE) +
guides(color = guide_legend(override.aes = list(size = 3))) +
theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 8),
legend.key.size = unit(0.3, 'cm'),
plot.margin = unit(c(0, 0.3, 0, 0),"cm"),
legend.position = "bottom") # ASW plot for final cluster
p2 = gg +
theme(axis.title.y = element_blank(),
plot.title = element_text(hjust = 0.5, face = "bold", size = 6),
axis.title.x=element_text(size = 5)) #boxplot for stability
p3 = fviz_dend(hc_cut5_ward, cex = 0.45, font.title = 10) +
labs(title = "Manhattan Distance-based Hierarchical Clustering Dendrogram") +
theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 10)) #final cluster dendogram
lay <- rbind(c(1,1,1,1,1,1,1,1,2,2,2,2),
c(1,1,1,1,1,1,1,1,2,2,2,2),
c(1,1,1,1,1,1,1,1,2,2,2,2),
c(1,1,1,1,1,1,1,1,3,3,3,3),
c(1,1,1,1,1,1,1,1,3,3,3,3)) #layout of the combined plots
figure2 = text_grob("Figure 3: Best Socioeconomic clusters", size = 15)
grid.arrange(p3, p1, p2, layout_matrix = lay, bottom = figure2) #visualise as 1 plot
hierarchical_5 = read.csv("hierarchical5.csv")
hierarchical_5
cluster5_df <- hierarchical_5 %>% dplyr::select(location, cluster) %>% rename(idx_cluster = cluster)
DTW_cluster = read.csv("latest_covid_cluster.csv")
covid_clust = dplyr::select(DTW_cluster, c("X", "location", "dtw_hclust")) %>% rename(covid_cluster = dtw_hclust)
covid_clust <- dplyr::select(covid_clust, -c("X"))
#Check to see if both clusters have the same length
length(covid_clust$location) == length(cluster5_df$location)
# turn indexes into facotr
covid_clust$covid_cluster <- as.factor(covid_clust$covid_cluster)
cluster5_df$idx_cluster <- as.factor(cluster5_df$idx_cluster)
combined_df = left_join(cluster5_df, covid_clust, by = "location")
# TO DOUBLE CHECK - should return 1
mean(cluster5_df$idx_cluster == combined_df$idx_cluster)
set.seed(3888)
columnm.names = combined_df$location
results_df = data.frame(matrix(ncol = 79, nrow = 1000))
colnames(results_df) <- columnm.names
# checking to see if clustering each iteration is consistent
for(i in 1:1000){
cluster.results <- kmodes(combined_df[2:3], 8,  iter.max = 100, weighted = FALSE)
results_df[i, ] <- cluster.results$cluster
}
results_df[] <- lapply(results_df, factor)
#checking all cluster modes of country to see if we can pick most common cluster assigned to each country
Modes <- function(x) {
ux <- unique(x)
tab <- tabulate(match(x, ux))
ux[tab == max(tab)]
}
cluster.mode <- lapply(results_df, Modes)
#NOT VIABLE METHOD!!!!! most common cluster was 1 for every country
rownames(combined_df) = combined_df$location
nm.clust2 <- nomclust(combined_df[2:3],  measure = "iof", method = "complete", clu.high = 16)
nm.clust2
par(cex=0.6)
#dend.plot(nm.clust2, clusters = "PSFE", main = "IOF Distance")
# FInding best K
eval.plot(nm.clust2, c("AIC"))
eval.plot(nm.clust2, c("WCE"))
eval.plot(nm.clust2, c("WCM"))
final_clust_IOF.hclust <- as.hclust(nm.clust2)
#cutting tree at optimal k
final_vector_IOF9 <- as.numeric(cutree(final_clust_IOF.hclust, k = 7))
xiof <- silhouette(final_vector_IOF9, iof(combined_df[2:3]))
par(cex=0.6)
dend.plot(nm.clust2, clusters = "AIC", main = "IOF Distance")
iof_asw_plot = fviz_silhouette(xiof) +
labs(caption = "Within-cluster Mutability: 0.341 with k = 7") +
theme(plot.caption = element_text(size = 10))
iof_asw_plot
rownames(combined_df) = combined_df$location
# Hierachical clustering based on LIN measure
nm.clust3 <- nomclust(combined_df[2:3],  measure = "lin", method = "complete", clu.high = 16)
par(mar = c(3, 5, 3, 3))
par(cex=0.6)
nm.clust3
#dend.plot(nm.clust3, clusters = "PSFE", main = "Dendrogram - lin distance")
eval.plot(nm.clust3, c("AIC"))
eval.plot(nm.clust3, c("WCE"))
eval.plot(nm.clust3, c("WCM"))
final_combined_df <- combined_df
final_clust8 <- nm.clust3
par(cex = 0.6)
dend.plot(final_clust8, clusters = "AIC", main = "LIN Dissimilarity Measure-based Hierarchical Clustering Dendrogram")
final_clust8.hclust <- as.hclust(final_clust8)
# cutting tree at optimal k
final_vector_8 <- as.numeric(cutree(final_clust8.hclust, k = 8))
final_combined_df$combined_cluster <- final_vector_8
write.csv(final_combined_df, "final_combined_clust1.csv")
# silhouette plot
x1 <- silhouette(final_vector_8 , lin(combined_df[2:3]))
lin_asw_plot = fviz_silhouette(x1) +
labs(caption = "Within-cluster Mutability: 0.305 with k = 8") +
theme(plot.caption = element_text(size = 10))
lin_asw_plot
library(mclust)
set.seed(3888)
n = 100
combined_result = c()
combined_df11 <- combined_df[2:3]
data_cpy <- final_combined_df
#evaluation method for stability
for (i in 1:n){
df.new <- combined_df11[-sample(1:nrow(combined_df11), 6),]
data.kept <- rownames(df.new)
data.subset = data_cpy[data_cpy$location %in% data.kept, ]
sub_cluster <- nomclust(df.new, measure = "lin", method = "complete", clu.high = 16)
sub_cluster <- as.hclust(sub_cluster)
sub_13k <- as.numeric(cutree(sub_cluster, k = 13))
adj_randI <- adjustedRandIndex(data.subset$combined_cluster, sub_13k)
combined_result[i] <- adj_randI
}
result11 <- as.data.frame(result)
final_clust_ari_p = result11 %>% ggplot() +
geom_boxplot(aes(x = result11$result), fill = "navy", alpha = 0.3) +
labs(x = "Adjusted Rand Index",
title = "Adjusted Rand Index Distribution of a 1000-time Simulation \nfor the Stability of LIN-based Hierarchical Clustering") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 14))
reticulate::repl_python()
mtcars %>% na.omit() %>% filter(am == 1) %>% mean(mpg)
library(tidyverse)
mtcars %>% na.omit() %>% filter(am == 1) %>% mean(mpg)
mtcars %>% na.omit(mpg) %>% filter(am == 1) %>% mean(mpg)
mtcars %>% filter(am == 1 & !is.na(mpg)) %>% mean(mpg)
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
opts_chunk$set(message = FALSE, warning = FALSE)
options(scipen = 999)
library(tidyverse)
library(tidyr)
library(knitr)
library(naniar)
library(vtable)
library(visdat)
library(reshape2)
library(here)
library(DT)
library(kableExtra)
library(scales)
library(qpcR)
library(fauxnaif)
# load technically correct biomedical data
path = here("tech_data.Rdata")
load(path)
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
opts_chunk$set(message = FALSE, warning = FALSE)
options(scipen = 999)
library(tidyverse)
library(tidyr)
library(knitr)
library(naniar)
library(vtable)
library(visdat)
library(reshape2)
library(here)
library(DT)
library(kableExtra)
library(scales)
library(qpcR)
library(fauxnaif)
# load technically correct biomedical data
path = here("tech_data.Rdata")
load(path)
load(path)
# load technically correct biomedical data
path = here("tech_data.Rdata")
# load technically correct biomedical data
path = here("tech_data.Rdata")
path
# load technically correct biomedical data
path = here("tech_data.Rdata")
path
# load technically correct biomedical data
path = here("tech_data.Rdata")
load(path)
